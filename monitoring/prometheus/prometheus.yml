# PROMETHEUS CONFIGURATION
#
# LEARNING POINTS:
# 1. Prometheus PULLS metrics from targets (HTTP GET /metrics)
# 2. Loki RECEIVES logs pushed from Promtail (HTTP POST)
# 3. This is the key difference: PULL vs PUSH model
# 4. Metrics are time-series data: counter, gauge, histogram, summary

global:
  scrape_interval: 15s      # How often to scrape targets
  evaluation_interval: 15s  # How often to evaluate rules
  scrape_timeout: 10s

  # Attach these labels to all time series
  external_labels:
    cluster: 'local'
    environment: 'development'

# Alertmanager configuration (optional - for alerting)
# alerting:
#   alertmanagers:
#     - static_configs:
#         - targets:
#           - alertmanager:9093

# Load rules once and periodically evaluate them
# rule_files:
#   - "rules/*.yml"

# SCRAPE CONFIGS - Define what endpoints to scrape for metrics
scrape_configs:
  # ========================================
  # Scrape Prometheus itself (meta-monitoring)
  # ========================================
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          service: 'prometheus'

  # ========================================
  # Scrape Loki metrics
  # ========================================
  - job_name: 'loki'
    static_configs:
      - targets: ['loki:3100']
        labels:
          service: 'loki'

  # ========================================
  # Scrape Grafana metrics
  # ========================================
  - job_name: 'grafana'
    static_configs:
      - targets: ['grafana:3000']
        labels:
          service: 'grafana'

  # ========================================
  # Scrape Your Rust Order Book API
  # ========================================
  # LEARNING: Your Rust app needs to expose a /metrics endpoint
  # Use the `prometheus` crate in Rust to expose metrics
  #
  # Example metrics you might track:
  # - order_book_orders_total{symbol="XAUUSD",side="buy"} 1234
  # - order_book_trades_total{symbol="EURUSD"} 567
  # - order_book_latency_seconds{operation="match_order"} 0.001
  # - fix_ticks_received_total{symbol="XAUUSD"} 10000
  #
  - job_name: 'order-book-api'
    # Replace with your app's actual host
    # If running on host: use host.docker.internal:3000
    # If running in Docker: use service name
    static_configs:
      - targets: ['host.docker.internal:3000']  # Adjust to your app's address
        labels:
          service: 'order-book-api'
          app: 'order-book-exchange'

    # Optional: Add HTTP basic auth if your metrics endpoint is protected
    # basic_auth:
    #   username: 'prometheus'
    #   password: 'secret'

    # Scrape interval for this specific job (override global)
    scrape_interval: 5s

    # Metrics path (default is /metrics)
    metrics_path: '/metrics'

    # Optional: Add relabeling to modify labels
    # metric_relabel_configs:
    #   - source_labels: [__name__]
    #     regex: 'go_.*'
    #     action: drop  # Drop Go runtime metrics if not needed

  # ========================================
  # Scrape RabbitMQ metrics (if you enable Prometheus plugin)
  # ========================================
  # RabbitMQ has a Prometheus plugin that exposes metrics
  # - job_name: 'rabbitmq'
  #   static_configs:
  #     - targets: ['host.docker.internal:15692']
  #       labels:
  #         service: 'rabbitmq'

  # ========================================
  # Scrape PostgreSQL metrics (using postgres_exporter)
  # ========================================
  # You can add postgres_exporter to monitor your databases
  # - job_name: 'postgres'
  #   static_configs:
  #     - targets: ['postgres-exporter:9187']
  #       labels:
  #         service: 'postgres'

# ========================================
# EXAMPLE QUERIES (PromQL)
# ========================================
# After setting up, try these queries in Prometheus UI (http://localhost:9090):
#
# 1. Rate of orders per second:
#    rate(order_book_orders_total[1m])
#
# 2. Orders grouped by symbol:
#    sum by (symbol) (order_book_orders_total)
#
# 3. 95th percentile latency:
#    histogram_quantile(0.95, rate(order_book_latency_seconds_bucket[5m]))
#
# 4. Memory usage:
#    process_resident_memory_bytes
#
# 5. CPU usage:
#    rate(process_cpu_seconds_total[1m])
